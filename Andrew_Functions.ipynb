{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn import preprocessing, metrics \n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "from keras.models import Model, Sequential\n",
    "from keras.wrappers.scikit_learn import KerasRegressor\n",
    "from keras.layers import Input, Dense, Activation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "#NOTE: none of these fxns are meant for single point input, input should always be a pd.DataFrame with more\n",
    "#than one row, not an unreasonable request since sklearn makes you reshape 1D arrays.\n",
    "\n",
    "\n",
    "# Data cleaning section: \n",
    "\n",
    "def split_and_scale(df, n):\n",
    "    \"\"\"Splits training dataframe into predictors and properties to be predicted and returns them in 2 new dfs.\n",
    "       This function assumes all of the predictors are grouped together on the right side of the df.\n",
    "       df_train: training df\n",
    "       n: number of properties to be predicted(number of outputs)\"\"\"\n",
    "    properties, predictors = split(df, n)\n",
    "    # COMMENT OUT THIS LINE IF YOU DONT WANT TO HAVE POLYNOMIAL TERMS IN YOUR TRAINING DATA\n",
    "    # But note that accuracy is much better with this, but the model will have higher variance\n",
    "    predictors_polynomial = polynomialize(predictors)\n",
    "    predictors_scaled_polynomial, predictors_scaler_polynomial = scaling(predictors_polynomial)\n",
    "    return properties, predictors_scaled_polynomial, predictors_scaler_polynomial \n",
    "\n",
    "\n",
    "def polynomialize(series):\n",
    "    \"\"\"Adds polynomial features to degree 3, including interaction features. \n",
    "    series: an input ndarray of floats to be polynomialized.\n",
    "    This function returns a ndarray of all of the features specified above.\"\"\"\n",
    "    # Creating polynomial object\n",
    "    poly = PolynomialFeatures(degree = 2)\n",
    "    # Adding polynomial terms\n",
    "    predictors_polynomial = poly.fit_transform(series)\n",
    "    return predictors_polynomial\n",
    "\n",
    "# Still in development, in case we want to add more terms that aren't polynomial\n",
    "# def add_nonlinear_terms(df, n):\n",
    "#     properties = df[df.columns[-n:]]\n",
    "#     predictors = df[df.columns[:-n]]\n",
    "#     i = np.arange(len(predictors.columns) * 4)\n",
    "#     x = 0\n",
    "#     for column in predictors.values:\n",
    "#         predictors.assign(i[x]=column**2)\n",
    "#         predictors.assign(column**3)\n",
    "#         predictors.assign(np.exp(column))\n",
    "#         predictors.assign(np.sign(column))\n",
    "#     return properties, predictors\n",
    "\n",
    "\n",
    "def split(df, n):\n",
    "    \"\"\"Takes an input pd.DataFrame and returns 2 ndarrays of the properties \n",
    "    and predictors.\"\"\"\n",
    "    properties = df[df.columns[-n:]].values\n",
    "    predictors = df[df.columns[:-n]].values\n",
    "    return properties, predictors\n",
    "\n",
    "\n",
    "def scaling(df_train):\n",
    "    \"\"\"This function takes a pd.DataFrame, creates a sklearn.StandardScaler, scales the DataFrame,\n",
    "       and returns the scaled data in a pd.DataFrame as well as the sklearn.StandardScaler object\n",
    "       for transforming data back to unscaled form post machine learning.\n",
    "       df_train: pd.DataFrame(for our purposes should be of shape 20 columns by an arbitrary number of rows)\"\"\"\n",
    "    #Creating scaler object\n",
    "    scaler = preprocessing.MinMaxScaler()\n",
    "    #Scaling df_train\n",
    "    scaled_data = pd.DataFrame(scaler.fit_transform(df_train))\n",
    "    \n",
    "    return scaled_data, scaler\n",
    "\n",
    "# Training/predicting\n",
    "\n",
    "\n",
    "def train_model(df_train, df_validation, model, n):\n",
    "    \"\"\"This function takes a training DataFrame, validation DataFrame and a preconfigured model\n",
    "       and trains said model on the training data followed by measuring error on validation data and \n",
    "       returning both the trained model and accuracy metric. This function assumes whatever parameter(s)\n",
    "       being predicted is in the last column(s) of df_train.\n",
    "       n: number of outputs\n",
    "       because this function returns the trained model, more metrics can be performed later that are specific\n",
    "       to whatever package it is in/the type of model it is\n",
    "       Parameters\"\"\"\n",
    "    #generating scaled data and their respective scaler objects\n",
    "    t_properties, t_predictors_scaled, t_predictors_scaler = split_and_scale(df_train, n)\n",
    "    v_properties, v_predictors_scaled, v_predictors_scaler = split_and_scale(df_validation, n)\n",
    "    #supervised learning of predictors and properties to fit model, note: keras does not take pd.DataFrames for\n",
    "    #training, using .values fixes this\n",
    "    model.fit(t_predictors_scaled, t_properties)\n",
    "    #predicting output of validation set\n",
    "    predictions = pd.DataFrame(model.predict(v_predictors_scaled))\n",
    "    #calculating RMSE from sklearn package\n",
    "    val_error = np.sqrt(metrics.mean_squared_error(predictions, v_properties))\n",
    "    return model, val_error, t_predictors_scaler\n",
    "\n",
    "\n",
    "def model_prediction(test_data, fitted_model, scaler, n):\n",
    "    \"\"\"Takes a fitted model and predicts the output of test data, returns the predicted data and accuracy.\n",
    "       THIS FUNCTION IS ONLY TO BE USED FOR FUTURE PREDICTIONS OR TESTING(WHICH SHOULD ONLY BE DONE ONCE).\n",
    "       Do not use this while training a model, that's what the validation data will be used for. We do not \n",
    "       want to introduce bias into our model by fitting to the test data\n",
    "       n = number of predictors\"\"\"\n",
    "    #splitting predictors and properties\n",
    "    properties, predictors = split(test_data, n)\n",
    "    predictors = polynomialize(predictors)\n",
    "    predictors_scaled = scaler.transform(predictors)\n",
    "    #predicting based on scaled input predictors\n",
    "    prediction = fitted_model.predict(predictors_scaled)\n",
    "    #calculating MSE\n",
    "    accuracy_metric = np.sqrt(metrics.mean_squared_error(properties, prediction))\n",
    "\n",
    "    return prediction, accuracy_metric\n",
    "\n",
    "# Below functions initialize all the different types of models we are looking at:\n",
    "\n",
    "\n",
    "def neural_network():\n",
    "    \"\"\"Creates a neural network object to be passed into train_model function, can change properties of net\n",
    "       here.\"\"\"\n",
    "    def model():\n",
    "        model = Sequential()\n",
    "        model.add(Dense(84, input_dim=84, kernel_initializer='normal', activation='relu'))\n",
    "        model.add(Dense(84, kernel_initializer='normal', activation='relu'))\n",
    "        model.add(Dense(1, kernel_initializer = 'normal'))#kernel_initializer = initial values of outputs i think\n",
    "        model.compile(optimizer='adam', loss='mse')\n",
    "        return model\n",
    "    network = KerasRegressor(build_fn=model, epochs=100, batch_size=25000, verbose=0)\n",
    "#     network.fit(x=None, y=None, batch_size=None, epochs=1, verbose=1, callbacks=None, validation_split=0.0, \n",
    "    return network\n",
    "\n",
    "\n",
    "def linear_regression():\n",
    "    \"\"\"creates a linear regression object\"\"\"\n",
    "    regr = LinearRegression()\n",
    "    return regr\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# to go in cleaning section\n",
    "# import clean\n",
    "\n",
    "def test_split():\n",
    "    data = {'column1': [2, 2, 3], 'column2': [1, 3, 5]}\n",
    "    df = pd.DataFrame(data)\n",
    "    one, two = clean.split(df, 1)\n",
    "    assert one[0] == 1\n",
    "    assert two[0] == 2\n",
    "    return\n",
    "\n",
    "def test_scaling():\n",
    "    data = {'column1': [2.0, 2.0, 3.0], 'column2': [1.0, 3.0, 5.0]}\n",
    "    df = pd.DataFrame(data)\n",
    "    df, scaler = clean.scaling(df)\n",
    "    assert df.loc[0].iloc[0] == 0\n",
    "    assert df.loc[2].iloc[0] == 1\n",
    "    return\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TO REDUCE OVERFITTING: reduce degree of polynomial terms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#model might just not have the right things\n",
    "#to reorder columns:\n",
    "#cols = df.columns.tolist()\n",
    "#df = df[cols] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from matminer.data_retrieval.retrieve_MP import MPDataRetrieval\n",
    "mpdr = MPDataRetrieval(api_key='x5He3oeSg1eCaIU4')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>amplitude_0</th>\n",
       "      <th>amplitude_1</th>\n",
       "      <th>amplitude_2</th>\n",
       "      <th>amplitude_3</th>\n",
       "      <th>amplitude_4</th>\n",
       "      <th>amplitude_5</th>\n",
       "      <th>amplitude_6</th>\n",
       "      <th>amplitude_7</th>\n",
       "      <th>amplitude_8</th>\n",
       "      <th>amplitude_9</th>\n",
       "      <th>...</th>\n",
       "      <th>two_theta_2</th>\n",
       "      <th>two_theta_3</th>\n",
       "      <th>two_theta_4</th>\n",
       "      <th>two_theta_5</th>\n",
       "      <th>two_theta_6</th>\n",
       "      <th>two_theta_7</th>\n",
       "      <th>two_theta_8</th>\n",
       "      <th>two_theta_9</th>\n",
       "      <th>band_gap</th>\n",
       "      <th>efermi</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>mp-1001113</th>\n",
       "      <td>100.0</td>\n",
       "      <td>78.288443</td>\n",
       "      <td>45.261343</td>\n",
       "      <td>40.440821</td>\n",
       "      <td>30.707488</td>\n",
       "      <td>26.515207</td>\n",
       "      <td>22.092113</td>\n",
       "      <td>21.737670</td>\n",
       "      <td>16.821364</td>\n",
       "      <td>16.690467</td>\n",
       "      <td>...</td>\n",
       "      <td>38.160738</td>\n",
       "      <td>171.874808</td>\n",
       "      <td>45.443514</td>\n",
       "      <td>176.442253</td>\n",
       "      <td>60.797841</td>\n",
       "      <td>148.648332</td>\n",
       "      <td>87.640251</td>\n",
       "      <td>80.839115</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>9.167451</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mp-1056579</th>\n",
       "      <td>100.0</td>\n",
       "      <td>91.828984</td>\n",
       "      <td>79.970463</td>\n",
       "      <td>45.423897</td>\n",
       "      <td>30.872127</td>\n",
       "      <td>26.312484</td>\n",
       "      <td>23.760237</td>\n",
       "      <td>15.234896</td>\n",
       "      <td>14.045885</td>\n",
       "      <td>13.052846</td>\n",
       "      <td>...</td>\n",
       "      <td>37.945623</td>\n",
       "      <td>73.006051</td>\n",
       "      <td>140.704562</td>\n",
       "      <td>54.746898</td>\n",
       "      <td>123.597176</td>\n",
       "      <td>85.886608</td>\n",
       "      <td>135.942882</td>\n",
       "      <td>93.269152</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>10.142574</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mp-1072544</th>\n",
       "      <td>100.0</td>\n",
       "      <td>74.250236</td>\n",
       "      <td>32.864700</td>\n",
       "      <td>32.201109</td>\n",
       "      <td>18.813035</td>\n",
       "      <td>17.053640</td>\n",
       "      <td>15.411324</td>\n",
       "      <td>14.668014</td>\n",
       "      <td>14.527636</td>\n",
       "      <td>13.937115</td>\n",
       "      <td>...</td>\n",
       "      <td>46.743236</td>\n",
       "      <td>32.580631</td>\n",
       "      <td>160.193335</td>\n",
       "      <td>50.741974</td>\n",
       "      <td>54.524230</td>\n",
       "      <td>42.462094</td>\n",
       "      <td>26.480052</td>\n",
       "      <td>98.859603</td>\n",
       "      <td>0.1444</td>\n",
       "      <td>3.791856</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mp-109</th>\n",
       "      <td>100.0</td>\n",
       "      <td>71.345225</td>\n",
       "      <td>64.937703</td>\n",
       "      <td>44.646425</td>\n",
       "      <td>31.309877</td>\n",
       "      <td>23.430551</td>\n",
       "      <td>18.238651</td>\n",
       "      <td>16.929197</td>\n",
       "      <td>15.766726</td>\n",
       "      <td>15.187868</td>\n",
       "      <td>...</td>\n",
       "      <td>36.713745</td>\n",
       "      <td>38.289916</td>\n",
       "      <td>54.089719</td>\n",
       "      <td>38.027277</td>\n",
       "      <td>90.802389</td>\n",
       "      <td>155.580355</td>\n",
       "      <td>162.010286</td>\n",
       "      <td>169.996134</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>9.233677</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mp-149</th>\n",
       "      <td>100.0</td>\n",
       "      <td>66.810009</td>\n",
       "      <td>39.697299</td>\n",
       "      <td>23.446055</td>\n",
       "      <td>19.431330</td>\n",
       "      <td>17.901536</td>\n",
       "      <td>16.361733</td>\n",
       "      <td>13.659079</td>\n",
       "      <td>12.509826</td>\n",
       "      <td>11.039952</td>\n",
       "      <td>...</td>\n",
       "      <td>55.749540</td>\n",
       "      <td>87.355760</td>\n",
       "      <td>126.141124</td>\n",
       "      <td>113.020106</td>\n",
       "      <td>75.826656</td>\n",
       "      <td>94.191997</td>\n",
       "      <td>155.193701</td>\n",
       "      <td>135.154370</td>\n",
       "      <td>0.6119</td>\n",
       "      <td>5.634221</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mp-16220</th>\n",
       "      <td>100.0</td>\n",
       "      <td>91.194330</td>\n",
       "      <td>82.558929</td>\n",
       "      <td>64.178610</td>\n",
       "      <td>58.432972</td>\n",
       "      <td>54.837508</td>\n",
       "      <td>39.433914</td>\n",
       "      <td>35.692211</td>\n",
       "      <td>30.283545</td>\n",
       "      <td>28.405679</td>\n",
       "      <td>...</td>\n",
       "      <td>52.695561</td>\n",
       "      <td>43.866856</td>\n",
       "      <td>17.015078</td>\n",
       "      <td>20.877953</td>\n",
       "      <td>170.458021</td>\n",
       "      <td>34.420518</td>\n",
       "      <td>165.871291</td>\n",
       "      <td>153.977258</td>\n",
       "      <td>0.5334</td>\n",
       "      <td>4.097343</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mp-165</th>\n",
       "      <td>100.0</td>\n",
       "      <td>76.453355</td>\n",
       "      <td>75.130992</td>\n",
       "      <td>62.759221</td>\n",
       "      <td>57.677657</td>\n",
       "      <td>51.843314</td>\n",
       "      <td>44.605352</td>\n",
       "      <td>32.784208</td>\n",
       "      <td>32.075634</td>\n",
       "      <td>30.306187</td>\n",
       "      <td>...</td>\n",
       "      <td>47.209853</td>\n",
       "      <td>30.257230</td>\n",
       "      <td>28.034159</td>\n",
       "      <td>166.986591</td>\n",
       "      <td>55.806977</td>\n",
       "      <td>39.124870</td>\n",
       "      <td>90.702622</td>\n",
       "      <td>130.816041</td>\n",
       "      <td>0.4517</td>\n",
       "      <td>5.898865</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mp-168</th>\n",
       "      <td>100.0</td>\n",
       "      <td>70.590906</td>\n",
       "      <td>66.583676</td>\n",
       "      <td>24.133148</td>\n",
       "      <td>18.174017</td>\n",
       "      <td>17.474408</td>\n",
       "      <td>14.443226</td>\n",
       "      <td>13.804826</td>\n",
       "      <td>11.952374</td>\n",
       "      <td>11.798358</td>\n",
       "      <td>...</td>\n",
       "      <td>170.276770</td>\n",
       "      <td>91.125960</td>\n",
       "      <td>26.789507</td>\n",
       "      <td>55.202796</td>\n",
       "      <td>151.438382</td>\n",
       "      <td>116.678065</td>\n",
       "      <td>78.754528</td>\n",
       "      <td>140.441238</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>7.052171</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mp-571520</th>\n",
       "      <td>100.0</td>\n",
       "      <td>43.334802</td>\n",
       "      <td>40.005817</td>\n",
       "      <td>32.918980</td>\n",
       "      <td>32.076427</td>\n",
       "      <td>30.139918</td>\n",
       "      <td>29.994833</td>\n",
       "      <td>25.861406</td>\n",
       "      <td>24.983342</td>\n",
       "      <td>21.405271</td>\n",
       "      <td>...</td>\n",
       "      <td>32.854949</td>\n",
       "      <td>51.589783</td>\n",
       "      <td>51.187368</td>\n",
       "      <td>170.098781</td>\n",
       "      <td>55.391229</td>\n",
       "      <td>52.089674</td>\n",
       "      <td>168.027021</td>\n",
       "      <td>51.288184</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>7.133047</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mp-676011</th>\n",
       "      <td>100.0</td>\n",
       "      <td>63.941827</td>\n",
       "      <td>37.274526</td>\n",
       "      <td>36.587043</td>\n",
       "      <td>34.737404</td>\n",
       "      <td>33.876036</td>\n",
       "      <td>30.127408</td>\n",
       "      <td>28.958163</td>\n",
       "      <td>28.511417</td>\n",
       "      <td>27.622809</td>\n",
       "      <td>...</td>\n",
       "      <td>27.177174</td>\n",
       "      <td>32.059515</td>\n",
       "      <td>45.915358</td>\n",
       "      <td>36.283100</td>\n",
       "      <td>38.803881</td>\n",
       "      <td>51.718617</td>\n",
       "      <td>20.404388</td>\n",
       "      <td>35.420940</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>6.383710</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mp-92</th>\n",
       "      <td>100.0</td>\n",
       "      <td>89.519568</td>\n",
       "      <td>62.160853</td>\n",
       "      <td>35.491127</td>\n",
       "      <td>32.998145</td>\n",
       "      <td>28.177716</td>\n",
       "      <td>23.375238</td>\n",
       "      <td>21.046731</td>\n",
       "      <td>20.371718</td>\n",
       "      <td>18.703673</td>\n",
       "      <td>...</td>\n",
       "      <td>54.973883</td>\n",
       "      <td>170.318665</td>\n",
       "      <td>53.901219</td>\n",
       "      <td>100.992171</td>\n",
       "      <td>77.282394</td>\n",
       "      <td>80.611442</td>\n",
       "      <td>116.942899</td>\n",
       "      <td>141.292439</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>9.072716</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mp-971661</th>\n",
       "      <td>100.0</td>\n",
       "      <td>99.182316</td>\n",
       "      <td>80.063286</td>\n",
       "      <td>62.811775</td>\n",
       "      <td>56.968090</td>\n",
       "      <td>49.392133</td>\n",
       "      <td>39.908017</td>\n",
       "      <td>35.661016</td>\n",
       "      <td>20.841327</td>\n",
       "      <td>20.014402</td>\n",
       "      <td>...</td>\n",
       "      <td>21.548360</td>\n",
       "      <td>17.559291</td>\n",
       "      <td>56.127271</td>\n",
       "      <td>51.153059</td>\n",
       "      <td>49.417713</td>\n",
       "      <td>30.659180</td>\n",
       "      <td>43.909877</td>\n",
       "      <td>45.802470</td>\n",
       "      <td>1.3309</td>\n",
       "      <td>4.153972</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mp-971662</th>\n",
       "      <td>100.0</td>\n",
       "      <td>83.862221</td>\n",
       "      <td>83.123090</td>\n",
       "      <td>67.861301</td>\n",
       "      <td>44.465923</td>\n",
       "      <td>33.962199</td>\n",
       "      <td>31.694816</td>\n",
       "      <td>31.422232</td>\n",
       "      <td>28.450868</td>\n",
       "      <td>28.101992</td>\n",
       "      <td>...</td>\n",
       "      <td>32.763921</td>\n",
       "      <td>21.280071</td>\n",
       "      <td>55.376756</td>\n",
       "      <td>36.213968</td>\n",
       "      <td>40.415643</td>\n",
       "      <td>30.272791</td>\n",
       "      <td>165.000511</td>\n",
       "      <td>52.967433</td>\n",
       "      <td>1.3094</td>\n",
       "      <td>3.882583</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mp-999200</th>\n",
       "      <td>100.0</td>\n",
       "      <td>96.530788</td>\n",
       "      <td>91.754612</td>\n",
       "      <td>44.663563</td>\n",
       "      <td>42.963074</td>\n",
       "      <td>26.871978</td>\n",
       "      <td>24.138237</td>\n",
       "      <td>23.501155</td>\n",
       "      <td>23.230589</td>\n",
       "      <td>23.106059</td>\n",
       "      <td>...</td>\n",
       "      <td>47.055157</td>\n",
       "      <td>54.895839</td>\n",
       "      <td>155.823774</td>\n",
       "      <td>38.045340</td>\n",
       "      <td>47.059389</td>\n",
       "      <td>54.899626</td>\n",
       "      <td>18.757983</td>\n",
       "      <td>42.741207</td>\n",
       "      <td>1.1826</td>\n",
       "      <td>5.320203</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>14 rows × 22 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            amplitude_0  amplitude_1  amplitude_2  amplitude_3  amplitude_4  \\\n",
       "mp-1001113        100.0    78.288443    45.261343    40.440821    30.707488   \n",
       "mp-1056579        100.0    91.828984    79.970463    45.423897    30.872127   \n",
       "mp-1072544        100.0    74.250236    32.864700    32.201109    18.813035   \n",
       "mp-109            100.0    71.345225    64.937703    44.646425    31.309877   \n",
       "mp-149            100.0    66.810009    39.697299    23.446055    19.431330   \n",
       "mp-16220          100.0    91.194330    82.558929    64.178610    58.432972   \n",
       "mp-165            100.0    76.453355    75.130992    62.759221    57.677657   \n",
       "mp-168            100.0    70.590906    66.583676    24.133148    18.174017   \n",
       "mp-571520         100.0    43.334802    40.005817    32.918980    32.076427   \n",
       "mp-676011         100.0    63.941827    37.274526    36.587043    34.737404   \n",
       "mp-92             100.0    89.519568    62.160853    35.491127    32.998145   \n",
       "mp-971661         100.0    99.182316    80.063286    62.811775    56.968090   \n",
       "mp-971662         100.0    83.862221    83.123090    67.861301    44.465923   \n",
       "mp-999200         100.0    96.530788    91.754612    44.663563    42.963074   \n",
       "\n",
       "            amplitude_5  amplitude_6  amplitude_7  amplitude_8  amplitude_9  \\\n",
       "mp-1001113    26.515207    22.092113    21.737670    16.821364    16.690467   \n",
       "mp-1056579    26.312484    23.760237    15.234896    14.045885    13.052846   \n",
       "mp-1072544    17.053640    15.411324    14.668014    14.527636    13.937115   \n",
       "mp-109        23.430551    18.238651    16.929197    15.766726    15.187868   \n",
       "mp-149        17.901536    16.361733    13.659079    12.509826    11.039952   \n",
       "mp-16220      54.837508    39.433914    35.692211    30.283545    28.405679   \n",
       "mp-165        51.843314    44.605352    32.784208    32.075634    30.306187   \n",
       "mp-168        17.474408    14.443226    13.804826    11.952374    11.798358   \n",
       "mp-571520     30.139918    29.994833    25.861406    24.983342    21.405271   \n",
       "mp-676011     33.876036    30.127408    28.958163    28.511417    27.622809   \n",
       "mp-92         28.177716    23.375238    21.046731    20.371718    18.703673   \n",
       "mp-971661     49.392133    39.908017    35.661016    20.841327    20.014402   \n",
       "mp-971662     33.962199    31.694816    31.422232    28.450868    28.101992   \n",
       "mp-999200     26.871978    24.138237    23.501155    23.230589    23.106059   \n",
       "\n",
       "            ...  two_theta_2  two_theta_3  two_theta_4  two_theta_5  \\\n",
       "mp-1001113  ...    38.160738   171.874808    45.443514   176.442253   \n",
       "mp-1056579  ...    37.945623    73.006051   140.704562    54.746898   \n",
       "mp-1072544  ...    46.743236    32.580631   160.193335    50.741974   \n",
       "mp-109      ...    36.713745    38.289916    54.089719    38.027277   \n",
       "mp-149      ...    55.749540    87.355760   126.141124   113.020106   \n",
       "mp-16220    ...    52.695561    43.866856    17.015078    20.877953   \n",
       "mp-165      ...    47.209853    30.257230    28.034159   166.986591   \n",
       "mp-168      ...   170.276770    91.125960    26.789507    55.202796   \n",
       "mp-571520   ...    32.854949    51.589783    51.187368   170.098781   \n",
       "mp-676011   ...    27.177174    32.059515    45.915358    36.283100   \n",
       "mp-92       ...    54.973883   170.318665    53.901219   100.992171   \n",
       "mp-971661   ...    21.548360    17.559291    56.127271    51.153059   \n",
       "mp-971662   ...    32.763921    21.280071    55.376756    36.213968   \n",
       "mp-999200   ...    47.055157    54.895839   155.823774    38.045340   \n",
       "\n",
       "            two_theta_6  two_theta_7  two_theta_8  two_theta_9  band_gap  \\\n",
       "mp-1001113    60.797841   148.648332    87.640251    80.839115    0.0000   \n",
       "mp-1056579   123.597176    85.886608   135.942882    93.269152    0.0000   \n",
       "mp-1072544    54.524230    42.462094    26.480052    98.859603    0.1444   \n",
       "mp-109        90.802389   155.580355   162.010286   169.996134    0.0000   \n",
       "mp-149        75.826656    94.191997   155.193701   135.154370    0.6119   \n",
       "mp-16220     170.458021    34.420518   165.871291   153.977258    0.5334   \n",
       "mp-165        55.806977    39.124870    90.702622   130.816041    0.4517   \n",
       "mp-168       151.438382   116.678065    78.754528   140.441238    0.0000   \n",
       "mp-571520     55.391229    52.089674   168.027021    51.288184    0.0000   \n",
       "mp-676011     38.803881    51.718617    20.404388    35.420940    0.0000   \n",
       "mp-92         77.282394    80.611442   116.942899   141.292439    0.0000   \n",
       "mp-971661     49.417713    30.659180    43.909877    45.802470    1.3309   \n",
       "mp-971662     40.415643    30.272791   165.000511    52.967433    1.3094   \n",
       "mp-999200     47.059389    54.899626    18.757983    42.741207    1.1826   \n",
       "\n",
       "               efermi  \n",
       "mp-1001113   9.167451  \n",
       "mp-1056579  10.142574  \n",
       "mp-1072544   3.791856  \n",
       "mp-109       9.233677  \n",
       "mp-149       5.634221  \n",
       "mp-16220     4.097343  \n",
       "mp-165       5.898865  \n",
       "mp-168       7.052171  \n",
       "mp-571520    7.133047  \n",
       "mp-676011    6.383710  \n",
       "mp-92        9.072716  \n",
       "mp-971661    4.153972  \n",
       "mp-971662    3.882583  \n",
       "mp-999200    5.320203  \n",
       "\n",
       "[14 rows x 22 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# This statements obtains and stores the relevant data from MPD\n",
    "# NOTE: Si was used as the criteria only for testing purposes. It will be changed later on\n",
    "MPD_data = mpdr.get_dataframe(criteria='Si', properties=['xrd', 'band_gap', 'efermi'])\n",
    "\n",
    "def extract_data(MPD_data_row):\n",
    "    \"\"\"\n",
    "    Extracts the relevant XRD data from the dictionary obtained from MPD\n",
    "    \n",
    "    Parameters:\n",
    "    ----------\n",
    "    MPD_data_row : Pandas dataframe\n",
    "         A row of data for a single material from the full MPD dataframe \n",
    "    \n",
    "    Returns:\n",
    "    ----------\n",
    "    clean_df: Pandas dataframe\n",
    "        The top 10 XRD peaks and their corresponding two theta values for the material\n",
    "    \"\"\"\n",
    "    \n",
    "    # Extracting out the amplitude and two theta values from the dictionary contained inside the received data\n",
    "    # then turning it into a pandas dataframe.\n",
    "    dirty_df = pd.DataFrame(MPD_data_row['xrd']['Cu']['pattern'], columns=MPD_data_row['xrd']['Cu']['meta']) # Converts data into dataframe\n",
    "    dirty_df.drop(['hkl','d_spacing'], axis=1, inplace=True) # Disposes of the hkl and d-spacing data\n",
    "\n",
    "    # Sorting the peaks into the top 10 with the highest peaks\n",
    "    dirty_df.sort_values('amplitude', ascending=False, inplace=True) # Sorts peaks from highest to smallest\n",
    "    dirty_df.reset_index(drop=True, inplace=True) # Reseting index\n",
    "    clean_df = dirty_df[:10] # Dropping all peaks below the top ten \n",
    "\n",
    "    return clean_df\n",
    "\n",
    "# Function to reformat the data after cleaning\n",
    "# Takes the dataframe and turns it into a dictionary wwhere all data points have a unique key\n",
    "def reformat_data(MPD_data_row):\n",
    "    \"\"\"\n",
    "    Reformats the cleaned data obtained from the extract_data function into a dictionary\n",
    "    \n",
    "    Parameters:\n",
    "    ----------\n",
    "    MPD_data_row : Pandas dataframe\n",
    "         A row of data for a single material from the full MPD dataframe \n",
    "    \n",
    "    Returns:\n",
    "    ----------\n",
    "    clean_df: Pandas dataframe\n",
    "        The top 10 XRD peaks and their corresponding two theta values for the material\n",
    "    \"\"\"\n",
    "    \n",
    "    # Cleaning data and creating empty dictionary\n",
    "    clean_df = extract_data(MPD_data_row)\n",
    "    mat_dict = {}\n",
    "\n",
    "    # Loop to assign each data point to a key and stores it within the dictionary\n",
    "    for i in range(0,20):\n",
    "        if i < 10:\n",
    "            amp_key = ('amplitude_' + str(i))\n",
    "            mat_dict[amp_key] = clean_df['amplitude'][i]\n",
    "\n",
    "        else:\n",
    "            theta_key = ('two_theta_' + str(i-10))\n",
    "            mat_dict[theta_key] = clean_df['two_theta'][i-10]\n",
    "\n",
    "    return mat_dict\n",
    "\n",
    "# Function \n",
    "def produce_data(MPD_data):\n",
    "    \"\"\"\n",
    "    Produces the XRD and DOS data for all the materials passed to the function \n",
    "    \n",
    "    Parameters:\n",
    "    ----------\n",
    "    MPD_data : Pandas dataframe\n",
    "      The dataframe filled with data obtained from MPD \n",
    "    \n",
    "    Returns:\n",
    "    ----------\n",
    "    full_df: Pandas dataframe\n",
    "        The peaks, two theta values, band gap, and fermi energy for all the materials passed to the function\n",
    "    \"\"\"\n",
    "    \n",
    "    # Creating prelimanry containers for XRD and DOS data\n",
    "    xrd_data = {}\n",
    "    dos_data = MPD_data.drop(['xrd'], axis=1)\n",
    "    \n",
    "    # Loop to run through each row of the dataframe\n",
    "    for i in range(len(MPD_data)):\n",
    "        \n",
    "        # Conditional to skip over materials with less than 10 XRD peaks\n",
    "        # or no fermi energies\n",
    "        if len(MPD_data.iloc[i]['xrd']['Cu']['pattern']) >= 10 and np.isnan(MPD_data.iloc[i]['efermi']) == False:\n",
    "            \n",
    "            # Obtaining and storing the XRD data for a material into a dictionary\n",
    "            ID = MPD_data.index[i]\n",
    "            mat_dict = reformat_data(MPD_data.iloc[i])\n",
    "            xrd_data[ID] = mat_dict\n",
    "            \n",
    "        else:\n",
    "            \n",
    "            # Replaces rows that failed the conditional with NaN\n",
    "            # This is for easy removal od the rows\n",
    "            dos_data.iloc[i] = float('nan')\n",
    "    \n",
    "    # Creating the final dataframe from the obtained XRD and DOS dataframes\n",
    "    dos_df = dos_data.dropna()\n",
    "    xrd_df = pd.DataFrame.from_dict(xrd_data, orient='index')\n",
    "    full_df = pd.concat([xrd_df, dos_df], axis=1, sort=False)\n",
    "    \n",
    "    return full_df\n",
    "\n",
    "produce_data(MPD_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# make sure inputs are correct, thats where shit gets fucked up\n",
    "d_train = produce_data(MPD_data)\n",
    "model, val_error, scaler = train_model(d_train.iloc[0:10], d_train.iloc[10:20],linear_regression(), 2)\n",
    "predictions, accuracy = model_prediction(d_train.iloc[0:2], model, scaler, 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-5.55111512e-17,  9.16745132e+00],\n",
       "       [ 8.32667268e-17,  1.01425740e+01]])"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.2570702125854891e-15"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
